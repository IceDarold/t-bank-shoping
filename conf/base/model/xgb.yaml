# ==============================================================================
# Полный файл конфигурации для XGBoost
# ==============================================================================
# Этот файл содержит большинство доступных параметров для XGBoost.
# Для получения самой последней и полной информации, обратитесь к официальной
# документации: https://xgboost.readthedocs.io/en/stable/parameter.html

# --- Указатель на Python-класс в нашем фреймворке ---
_target_: src.models.xgb.XGBModel

# --- Словарь с параметрами, передаваемый в конструктор класса ---
params:
  # ============================================================================
  # 1. Основные параметры задачи (General Parameters)
  # ============================================================================
  
  # `objective`: определяет функцию потерь для оптимизации.
  # - "binary:logistic": логистическая регрессия для бинарной классификации (выдает вероятности).
  # - "multi:softmax": для многоклассовой классификации (выдает предсказанный класс). Требует `num_class`.
  # - "multi:softprob": то же, что и softmax, но выдает вектор вероятностей для каждого класса.
  # - "reg:squarederror": регрессия с L2 ошибкой (RMSE).
  # - "reg:absoluteerror": регрессия с L1 ошибкой (MAE).
  objective: "binary:logistic"

  # `eval_metric`: метрика(и) для оценки на валидационном сете.
  # Можно передать список для отслеживания нескольких метрик.
  # - Классификация: "auc", "logloss", "error", "aucpr" (Area under PR curve).
  # - Регрессия: "rmse", "mae", "mape", "rmsle".
  eval_metric: "auc"

  # `base_score`: начальное предсказание для всех объектов. Обычно оставляют 0.5.
  base_score: 0.5
  
  # ============================================================================
  # 2. Параметры бустера (Booster Parameters)
  # ============================================================================

  # `booster`: тип модели для использования на каждой итерации.
  # - "gbtree": классический вариант на основе деревьев решений. Используется в 99% случаев.
  # - "gblinear": использует линейную модель на каждом шаге. Очень быстрый, но менее точный.
  # - "dart": вариант gbtree с использованием Dropout для борьбы с переобучением.
  booster: "gbtree"
  
  # --- DART Booster Specific Parameters (только если booster='dart') ---
  # `sample_type`: 'uniform' (выброшенные деревья выбираются случайно) или 'weighted' (по весам).
  # sample_type: 'uniform'
  # `normalize_type`: 'tree' или 'forest'.
  # normalize_type: 'tree'
  # `rate_drop`: доля деревьев, которые "выбрасываются" на каждой итрации (dropout rate).
  # rate_drop: 0.1
  # `skip_drop`: вероятность пропустить шаг dropout.
  # skip_drop: 0.5

  # ============================================================================
  # 3. Параметры древовидного бустера (Tree Booster Parameters)
  # ============================================================================
  # Эти параметры используются, только если booster='gbtree' или 'dart'.

  # `learning_rate` (или `eta`): коэффициент обучения. Уменьшает вклад каждого нового дерева.
  # Классический гиперпараметр для тюнинга. Типичные значения: 0.01 - 0.2.
  learning_rate: 0.05
  
  # `n_estimators`: количество деревьев (раундов бустинга). Управляется из `train.py`
  # через early stopping, но можно задать и здесь.
  n_estimators: 1000

  # --- Параметры для контроля сложности модели (регуляризация) ---

  # `max_depth`: максимальная глубина дерева. Ключевой параметр для контроля переобучения.
  # Типичные значения: 3 - 10.
  max_depth: 6
  
  # `min_child_weight`: минимальная сумма весов экземпляров (hessian), необходимая в дочернем узле.
  # Чем выше значение, тем более консервативной будет модель.
  min_child_weight: 1

  # `gamma` (или `min_split_loss`): минимальное снижение функции потерь, необходимое для
  # дальнейшего разделения узла. Задает "цену" нового ветвления.
  gamma: 0

  # `subsample`: доля строк (объектов), случайно выбираемых для построения каждого дерева.
  # Предотвращает переобучение. Типичные значения: 0.5 - 1.0.
  subsample: 0.8

  # `colsample_bytree`: доля признаков (колонок), случайно выбираемых для построения каждого дерева.
  colsample_bytree: 0.8
  # `colsample_bylevel`: доля признаков для каждого нового уровня глубины.
  # colsample_bylevel: 1
  # `colsample_bynode`: доля признаков для каждого нового ветвления.
  # colsample_bynode: 1

  # `reg_lambda` (L2 регуляризация, Ridge): коэффициент регуляризации на веса.
  reg_lambda: 1
  
  # `reg_alpha` (L1 регуляризация, Lasso): коэффициент регуляризации на веса.
  reg_alpha: 0
  
  # `max_delta_step`: Максимальный шаг, который может сделать вес листа. Обычно не используется.
  # max_delta_step: 0

  # `scale_pos_weight`: Контроль баланса классов. Устанавливается в `sum(negative instances) / sum(positive instances)`.
  # Очень полезно для несбалансированных датасетов.
  # scale_pos_weight: 1

  # ============================================================================
  # 4. Параметры производительности и железа
  # ============================================================================
  
  # `n_jobs`: количество потоков для параллелизации. -1 использует все доступные.
  n_jobs: -1

  # `tree_method`: алгоритм построения деревьев.
  # - 'auto': выбор по умолчанию (обычно 'hist').
  # - 'exact': точный жадный алгоритм. Медленный.
  # - 'approx': приближенный жадный алгоритм.
  # - 'hist': гистограммный алгоритм. Очень быстрый и эффективный. Рекомендуется.
  # - 'gpu_hist': версия 'hist' для GPU.
  tree_method: 'hist'

  # `max_bin`: используется только с `tree_method='hist'`. Количество "корзин" для числовых признаков.
  # max_bin: 256

  # --- GPU-специфичные параметры (только если tree_method='gpu_hist') ---
  # `predictor`: где выполнять предсказания - 'cpu_predictor' или 'gpu_predictor'.
  # predictor: 'auto'
  # `gpu_id`: ID графического процессора для использования.
  # gpu_id: 0

  # ============================================================================
  # 5. Прочие параметры
  # ============================================================================
  
  # `seed` (или `random_state`): сид для воспроизводимости.
  seed: ${globals.seed}

  # `verbosity`: уровень выводимой информации.
  # 0 (silent), 1 (warning), 2 (info), 3 (debug).
  verbosity: 1