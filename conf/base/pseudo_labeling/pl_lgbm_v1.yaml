# ==============================================================================
# Конфигурация для пайплайна Псевдо-лейблинга
# ==============================================================================
# Имя этого конкретного эксперимента по псевдо-лейблингу.
# Используется для именования артефактов и логов.
name: "pl_lgbm_v1"

# --- 1. Основные параметры процесса ---

# Количество итераций (раундов) псевдо-лейблинга после начального обучения.
# `num_rounds: 2` означает: 1 начальное обучение + 2 раунда переобучения.
num_rounds: 2

# --- 2. Параметры отбора псевдо-меток ---

# Список порогов уверенности для каждого раунда.
# Длина этого списка должна быть равна `num_rounds`.
confidence_thresholds:
  # Раунд 1: используем очень строгие пороги, чтобы добавить только самые
  # надежные метки.
  - high: 0.98  # Вероятность > 98% для класса 1
    low: 0.02   # Вероятность < 2% для класса 0

  # Раунд 2: можно немного ослабить пороги, так как модель стала сильнее.
  - high: 0.95
    low: 0.05

# --- 3. Конфигурация "строительных блоков" ---

# Имя конфигурации `feature_engineering` (из папки `conf/feature_engineering/`),
# которая будет использоваться на каждом раунде для перегенерации признаков.
# Важно выбрать конфиг с мощными агрегационными или target-based признаками,
# так как именно они получат наибольшую выгоду от новых данных.
feature_engineering_config: "v12_with_aggregations"

# Имя конфигурации `experiment` (из папки `conf/experiment/`),
# которая будет использоваться на каждом раунде для переобучения модели.
# Этот конфиг определяет, какая модель (LGBM, XGBoost), с какими параметрами,
# на какой валидации и с какой метрикой будет обучаться.
training_experiment_config: "exp001_lgbm_baseline"


# --- 4. Технические параметры ---

# Путь к временной директории, куда будут сохраняться промежуточные
# датасеты (расширенные train.csv). Путь относителен корня проекта.
temp_data_path: "data/99_temp_pseudo_labeling/"