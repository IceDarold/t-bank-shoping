# ==============================================================================
# Конфигурация для генерации признаков с помощью Denoising Autoencoder
# ==============================================================================
# Этот конвейер состоит из одного шага, который применяет self-supervised
# обучение для создания высокоуровневых представлений данных.

# Имя этого набора признаков (и артефакта W&B)
name: "features_with_ssl_ae"

pipeline:
  # === Шаг 1: Self-Supervised Pre-training с помощью Автоэнкодера ===
  - _target_: src.features.advanced.autoencoder.AutoencoderFeatureGenerator
    name: "ae_features"
    
    # --------------------------------------------------------------------------
    # 1. Выбор признаков для обучения автоэнкодера
    # --------------------------------------------------------------------------
    # Здесь нужно перечислить все числовые признаки, которые вы хотите
    # использовать для обучения представления. Это могут быть как сырые,
    # так и уже сгенерированные признаки (например, агрегации).
    # ВАЖНО: Признаки должны быть числовыми.
    # Этот список нужно будет адаптировать под ваш конкретный набор данных.
    feature_cols:
      # - "age"
      # - "income"
      # - "user_id_mean_transaction_amount"
      # - "user_id_std_transaction_amount"
      # - "city_te" # Target-encoded признаки тоже хорошо подходят
      # - "description_tfidf_pca_0" # Компоненты PCA из текста
      # - "description_tfidf_pca_1"
      # - ... и так далее
      # ❗️ ЗАПОЛНИТЕ ЭТОТ СПИСОК СВОИМИ ЛУЧШИМИ ЧИСЛОВЫМИ ПРИЗНАКАМИ

    # --------------------------------------------------------------------------
    # 2. Гиперпараметры Архитектуры Автоэнкодера
    # --------------------------------------------------------------------------
    
    # `bottleneck_dim`: Размерность "бутылочного горлышка", т.е. количество
    # новых признаков, которые будут сгенерированы.
    bottleneck_dim: 32

    # `layers`: Список размеров скрытых слоев в кодировщике (декодировщик
    # будет построен симметрично).
    layers: [256, 128]

    # `dropout`: Коэффициент dropout для регуляризации.
    dropout: 0.2

    # --------------------------------------------------------------------------
    # 3. Гиперпараметры Обучения Автоэнкодера
    # --------------------------------------------------------------------------
    
    # `noise_level`: Уровень "порчи" входных данных. Стандартное отклонение
    # Гауссова шума, добавляемого к каждому батчу. 0.0 - обычный автоэнкодер,
    # 0.1-0.2 - хороший выбор для Denoising Autoencoder.
    noise_level: 0.1

    # `epochs`: Количество эпох для обучения.
    epochs: 20
    
    # `batch_size`: Размер батча.
    batch_size: 512
    
    # `optimizer_params`: Параметры для PyTorch оптимизатора (AdamW).
    optimizer_params:
      lr: 0.001
      weight_decay: 1e-5