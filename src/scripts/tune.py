# src/tune.py

from pathlib import Path
import warnings

import hydra
from omegaconf import DictConfig, OmegaConf, open_dict
import optuna
from optuna_integration import WandbCallback
import wandb

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à—É –æ—Å–Ω–æ–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è
from src.train import train

warnings.filterwarnings("ignore", category=optuna.exceptions.ExperimentalWarning)


# ==================================================================================
# Objective Function
# ==================================================================================
def objective(trial: optuna.trial.Trial, cfg: DictConfig) -> float:
    """
    "–¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è" –¥–ª—è Optuna.

    –ù–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è:
    1. –ü–æ–ª—É—á–∞–µ—Ç –æ—Ç Optuna `trial` —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.
    2. –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —ç—Ç–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∫–æ–ø–∏—é –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞.
    3. –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω `train.py` —Å –Ω–æ–≤—ã–º –∫–æ–Ω—Ñ–∏–≥–æ–º.
    4. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π OOF-—Å–∫–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π Optuna –ø—ã—Ç–∞–µ—Ç—Å—è –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å.
    """
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∫–æ–Ω—Ñ–∏–≥–∞, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª –º–µ–∂–¥—É trials
    trial_cfg = cfg.copy()
    
    # --- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ `search_space` ---
    with open_dict(trial_cfg): # –ü–æ–∑–≤–æ–ª—è–µ–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥
        for param_path, search_space in cfg.tuning.search_space.items():
            param_type = search_space.type
            param_name = param_path.split('.')[-1]
            
            # –ö–æ–ø–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è suggest, —É–¥–∞–ª—è—è –Ω–∞—à 'type'
            suggest_params = {k: v for k, v in search_space.items() if k != 'type'}

            if param_type == 'float':
                value = trial.suggest_float(param_name, **suggest_params)
            elif param_type == 'int':
                value = trial.suggest_int(param_name, **suggest_params)
            elif param_type == 'categorical':
                value = trial.suggest_categorical(param_name, **suggest_params['choices'])
            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: {param_type}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –æ–±—ä–µ–∫—Ç–µ –∫–æ–Ω—Ñ–∏–≥–∞
            OmegaConf.update(trial_cfg, param_path, value)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å –Ω–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    try:
        oof_score = train(trial_cfg)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è trial: {e}. Optuna –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —ç—Ç–æ –∫–∞–∫ –Ω–µ—É–¥–∞—á–Ω—ã–π –∑–∞–ø—É—Å–∫.")
        raise optuna.exceptions.TrialPruned()
        
    return oof_score

# ==================================================================================
# Main Tuning Function
# ==================================================================================
@hydra.main(config_path="../conf", config_name="config", version_base=None)
def tune(cfg: DictConfig) -> None:
    """
    –ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
    """
    start_time = time.time()
    
    # --- 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ---
    print("--- –ó–∞–ø—É—Å–∫ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ---")
    print("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç—é–Ω–∏–Ω–≥–∞:")
    print(OmegaConf.to_yaml(cfg.tuning))
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º W&B Callback –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Optuna
    wandb_callback = WandbCallback(
        metric_name=f"oof_score_{cfg.metric.main._target_.split('.')[-1].replace('Metric','')}_mean",
        wandb_kwargs={
            "project": cfg.wandb.project,
            "entity": cfg.wandb.entity,
            "job_type": "tuning"
        },
        as_multirun=True, # –õ–æ–≥–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π trial –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π W&B run
    )

    # --- 2. –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è" Optuna ---
    study = optuna.create_study(
        direction=cfg.tuning.direction,
        study_name=f"{cfg.model._target_.split('.')[-2]}-{cfg.features.name}-tuning"
    )

    study.optimize(
        lambda trial: objective(trial, cfg),
        n_trials=cfg.tuning.n_trials,
        callbacks=[wandb_callback]
    )

    # --- 3. –ê–Ω–∞–ª–∏–∑ –∏ –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    print("\n--- –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω ---")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö trials: {len(study.trials)}")
    
    best_trial = study.best_trial
    print("\n--- –õ—É—á—à–∏–π trial ---")
    print(f"  Value (OOF Score): {best_trial.value:.5f}")
    print("  Params: ")
    for key, value in best_trial.params.items():
        print(f"    {key}: {value}")

    # --- 4. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ "—Ç—é–Ω–∏–Ω–≥–æ–≤–∞–Ω–Ω–æ–≥–æ" –∫–æ–Ω—Ñ–∏–≥–∞ ---
    print("\n--- –°–æ–∑–¥–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—é–Ω–∏–Ω–≥–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞ –º–æ–¥–µ–ª–∏ ---")
    
    base_model_config = cfg.model.copy()
    
    # –£–¥–∞–ª—è–µ–º _target_ –Ω–∞ –≤—Ä–µ–º—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å OmegaConf
    target_path = base_model_config.pop('_target_')
    
    # –û–±–Ω–æ–≤–ª—è–µ–º `params` –≤ –±–∞–∑–æ–≤–æ–º –∫–æ–Ω—Ñ–∏–≥–µ –ª—É—á—à–∏–º–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    with open_dict(base_model_config):
        for key, value in best_trial.params.items():
            # –ù–∞—Ö–æ–¥–∏–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞—Ä–∞–º–µ—Ç—Ä—É –≤ search_space
            full_param_path = next((path for path in cfg.tuning.search_space if path.endswith(key)), None)
            if full_param_path:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ `params` —á–∞—Å—Ç—å
                relative_path = ".".join(full_param_path.split('.')[1:])
                OmegaConf.update(base_model_config, relative_path, value)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º _target_ –Ω–∞ –º–µ—Å—Ç–æ
    base_model_config['_target_'] = target_path

    # --- 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ ---
    # –ü–æ–ª—É—á–∞–µ–º ID –≥–ª–∞–≤–Ω–æ–≥–æ W&B run'–∞, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞–ª callback
    main_wandb_run = wandb.run or wandb.Api().run(wandb_callback.wandb_runs[0])
    
    tuned_model_name = f"{cfg.model._target_.split('.')[-2]}_tuned_{main_wandb_run.id}"
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
    output_dir = Path(hydra.utils.get_original_cwd()) / "conf/model"
    output_dir.mkdir(parents=True, exist_ok=True)
    output_filepath = output_dir / f"{tuned_model_name}.yaml"
    
    with open(output_filepath, 'w') as f:
        OmegaConf.save(config=base_model_config, f=f)
    print(f"–¢—é–Ω–∏–Ω–≥–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ: {output_filepath}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –≤ W&B
    artifact = wandb.Artifact(
        name=f"config-{tuned_model_name}",
        type="model-config",
    )
    artifact.add_file(str(output_filepath))
    main_wandb_run.log_artifact(artifact)
    print(f"–ê—Ä—Ç–µ—Ñ–∞–∫—Ç —Å –∫–æ–Ω—Ñ–∏–≥–æ–º '{artifact.name}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ W&B.")
    print("\nüí° –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É –º–æ–¥–µ–ª—å –≤ `train.py`, —É–∫–∞–∑–∞–≤ "
          f"`model={tuned_model_name}`")
    
    main_wandb_run.finish()

if __name__ == "__main__":
    tune()